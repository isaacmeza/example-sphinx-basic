{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the simulations/mcpy directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../simulations')))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import simulations.dgps_mediated as dgps\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso, LassoCV, LogisticRegression, LogisticRegressionCV, LinearRegression,\\\n",
    "    ElasticNet, ElasticNetCV, MultiTaskElasticNet, MultiTaskElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nnpiv.ensemble import EnsembleIV, EnsembleIVStar\n",
    "from nnpiv.rkhs import ApproxRKHSIVCV, RKHSIVCV\n",
    "from nnpiv.shape import LipschitzShapeIV, ShapeIV\n",
    "from nnpiv.linear import OptimisticHedgeVsOptimisticHedge, StochasticOptimisticHedgeVsOptimisticHedge\n",
    "from nnpiv.linear import L2OptimisticHedgeVsOGD, L2ProxGradient\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.cluster import KMeans\n",
    "#from nnpiv.neuralnet.deepiv_fit import deep_iv_fit\n",
    "from nnpiv.neuralnet.rbflayer import gaussian, inverse_multiquadric\n",
    "from nnpiv.neuralnet import AGMM, KernelLayerMMDGMM, CentroidMMDGMM, KernelLossAGMM, MMDGMM\n",
    "from nnpiv.tsls import tsls, regtsls\n",
    "\n",
    "p = 0.1  # dropout prob of dropout layers throughout notebook\n",
    "n_hidden = 100  # width of hidden layers throughout notebook\n",
    "\n",
    "# For any method that use a projection of z into features g(z)\n",
    "g_features = 100\n",
    "\n",
    "# The kernel function\n",
    "kernel_fn = gaussian\n",
    "# kernel_fn = inverse_multiquadric\n",
    "\n",
    "# Training params\n",
    "learner_lr = 1e-4\n",
    "adversary_lr = 1e-4\n",
    "learner_l2 = 1e-3\n",
    "adversary_l2 = 1e-4\n",
    "adversary_norm_reg = 1e-3\n",
    "n_epochs = 300\n",
    "bs = 100\n",
    "sigma = 2.0 / g_features\n",
    "n_centers = 100\n",
    "device = torch.cuda.current_device() if torch.cuda.is_available() else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnpiv.semiparametrics import DML_mediated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10518, 34)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('../data/JCdata.csv', delimiter=' ', header=0)\n",
    "\n",
    "# Bind covariates\n",
    "X = df[[\"female\", \"age\", \"race_white\", \"race_black\", \"race_hispanic\", \"educ_geddiploma\",\n",
    "        \"educ_hsdiploma\", \"ntv_engl\", \"marstat_divorced\", \"marstat_separated\",\n",
    "        \"marstat_livetogunm\", \"marstat_married\", \"haschldY0\", \"everwkd\", \"mwearn\",\n",
    "        \"hohhd0\", \"nonres\", \"g10\", \"g10missdum\", \"work_dad_didnotwork\", \"g2\", \"g5\",\n",
    "        \"g7\", \"welfare_child\", \"welfare_childmissdum\", \"h1_fair_poor\", \"h2\", \"h29\",\n",
    "        \"h5\", \"h5missdum\", \"h7\", \"h7missdum\", \"i1\", \"i10\"]][df[\"e12missdum\"] == 0].values\n",
    "\n",
    "df['a'] = df['d'][df[\"e12missdum\"] == 0].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Create proxies\n",
    "Z = df[[\"e12\", \"e37\"]][df[\"e12missdum\"] == 0].values\n",
    "W = df[[\"e32\", \"e8_recruitersoffice\"]][df[\"e12missdum\"] == 0].values\n",
    "\n",
    "\n",
    "# Outcome\n",
    "Y = df[[\"y\"]][df[\"e12missdum\"] == 0].values\n",
    "# Mediator\n",
    "M = df[[\"m\"]][df[\"e12missdum\"] == 0].values\n",
    "# Treatment\n",
    "D = df[[\"a\"]][df[\"e12missdum\"] == 0].values\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rkhs_model = ApproxRKHSIVCV(kernel_approx='nystrom', n_components=100,\n",
    "                           kernel='rbf', gamma=.1, delta_scale='auto',\n",
    "                           delta_exp=.4, alpha_scales=np.geomspace(1, 10000, 10), cv=5)\n",
    "\n",
    "def _get_learner(n_t):\n",
    "    return nn.Sequential(nn.Dropout(p=p), nn.Linear(n_t, n_hidden), nn.LeakyReLU(),\n",
    "                         nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "\n",
    "\n",
    "def _get_adversary(n_z):\n",
    "    return nn.Sequential(nn.Dropout(p=p), nn.Linear(n_z, n_hidden), nn.LeakyReLU(),\n",
    "                         nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "\n",
    "\n",
    "def _get_adversary_g(n_z):\n",
    "    return nn.Sequential(nn.Dropout(p=p), nn.Linear(n_z, n_hidden), nn.LeakyReLU(),\n",
    "                         nn.Dropout(p=p), nn.Linear(n_hidden, g_features), nn.ReLU())\n",
    "\n",
    "\n",
    "agmm_1 = AGMM(_get_learner(37),_get_adversary(37))\n",
    "agmm_2 = AGMM(_get_learner(36),_get_adversary(36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dml_rkhs = DML_mediated(Y, D, M, W, Z, X,\n",
    "                        estimand='E[Y(1,M(0))]',\n",
    "                        model1 = ApproxRKHSIVCV(kernel_approx='nystrom', n_components=1000,\n",
    "                           kernel='rbf', gamma=.1, delta_scale='auto',\n",
    "                           delta_exp=.4, alpha_scales=np.geomspace(1, 10000, 10), cv=10),\n",
    "                        model2 = ApproxRKHSIVCV(kernel_approx='nystrom', n_components=100,\n",
    "                           kernel='rbf', gamma=.1, delta_scale='auto',\n",
    "                           delta_exp=.4, alpha_scales=np.geomspace(1, 10000, 10), cv=5),\n",
    "                        modelq1 = ApproxRKHSIVCV(kernel_approx='nystrom', n_components=100,\n",
    "                           kernel='rbf', gamma=.1, delta_scale='auto',\n",
    "                           delta_exp=.4, alpha_scales=np.geomspace(1, 10000, 10), cv=5),\n",
    "                        modelq2 = ApproxRKHSIVCV(kernel_approx='nystrom', n_components=100,\n",
    "                           kernel='rbf', gamma=.1, delta_scale='auto',\n",
    "                           delta_exp=.4, alpha_scales=np.geomspace(1, 10000, 10), cv=5),\n",
    "                n_folds=5, n_rep=1, CHIM = False, prop_score=LogisticRegression(max_iter=1000))\n",
    "                \n",
    "dml_rkhs_chim = DML_mediated(Y, D, M, W, Z, X,\n",
    "                        estimand='Direct',     \n",
    "                        model1 = rkhs_model,\n",
    "                        model2 = rkhs_model,\n",
    "                        modelq1 = rkhs_model,\n",
    "                        modelq2 = rkhs_model,\n",
    "                n_folds=5, n_rep=3, CHIM = True, prop_score=LogisticRegression(max_iter=2000))\n",
    "\n",
    "dml_rkhs_ipw = DML_mediated(Y, D, M, W, Z, X,\n",
    "                        estimand='Direct',\n",
    "                        model1 = rkhs_model,\n",
    "                        model2 = rkhs_model,\n",
    "                        modelq1 = rkhs_model,\n",
    "                        modelq2 = rkhs_model,\n",
    "                n_folds=5, n_rep=3, estimator='IPW', prop_score=LogisticRegression(max_iter=2000))\n",
    "\n",
    "dml_rkhs_ipw_chim = DML_mediated(Y, D, M, W, Z, X,\n",
    "                        estimand='Direct',\n",
    "                        model1 = rkhs_model,\n",
    "                        model2 = rkhs_model,\n",
    "                        modelq1 = rkhs_model,\n",
    "                        modelq2 = rkhs_model,\n",
    "                n_folds=5, n_rep=3, estimator='IPW', CHIM = True, prop_score=LogisticRegression(max_iter=2000))                \n",
    "\n",
    "dml_agmm = DML_mediated(Y, D, M, W, Z, X,\n",
    "                        estimand='Direct',\n",
    "                        model1 = agmm_1,\n",
    "                        model2 = agmm_2,\n",
    "                        modelq1 = agmm_2,\n",
    "                        modelq2 = agmm_1,\n",
    "                        n_folds=5, n_rep=1,\n",
    "                        CHIM = False,\n",
    "                        prop_score=LogisticRegression(max_iter=2000),\n",
    "                        nn_1 = True,\n",
    "                        nn_2 = True,\n",
    "                        nn_q1 = True,\n",
    "                        nn_q2 = True,\n",
    "                        fitargs1 = {'n_epochs': 300, 'bs': 100, 'learner_lr': 1e-4, 'adversary_lr': 1e-4, 'learner_l2': 1e-3, 'adversary_l2': 1e-4, 'adversary_norm_reg' : 1e-3},\n",
    "                        fitargs2 = {'n_epochs': 300, 'bs': 100, 'learner_lr': 1e-4, 'adversary_lr': 1e-4, 'learner_l2': 1e-3, 'adversary_l2': 1e-4},\n",
    "                        fitargsq1 = {'n_epochs': 300, 'bs': 100, 'learner_lr': 1e-4, 'adversary_lr': 1e-4, 'learner_l2': 1e-3, 'adversary_l2': 1e-4},\n",
    "                        fitargsq2 = {'n_epochs': 300, 'bs': 100, 'learner_lr': 1e-4, 'adversary_lr': 1e-4, 'learner_l2': 1e-3, 'adversary_l2': 1e-4},\n",
    "                        opts = {'lin_degree': 1, 'burnin': 200})\n",
    "\n",
    "dml_2sls = DML_mediated(Y, D, M, W, Z, X,\n",
    "                        estimand='Direct',\n",
    "                        model1 = tsls(),\n",
    "                        model2 = tsls(),\n",
    "                        modelq1 = tsls(),\n",
    "                        modelq2 = tsls(),\n",
    "                n_folds=10, n_rep=3, prop_score=LogisticRegression(max_iter=6000))\n",
    "\n",
    "\n",
    "dml_rfiv = DML_mediated(Y, D, M, W, Z, X,\n",
    "                        estimand='Direct',\n",
    "                        model1 = EnsembleIV(n_iter=200, max_abs_value=2),\n",
    "                        model2 = EnsembleIV(n_iter=200, max_abs_value=2),\n",
    "                        modelq1 = EnsembleIV(n_iter=200, max_abs_value=2),\n",
    "                        modelq2 = EnsembleIV(n_iter=200, max_abs_value=2),\n",
    "                n_folds=5, n_rep=1, prop_score=LogisticRegression(max_iter=1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:55<00:00,  5.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:53<00:00,  5.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:54<00:00,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.1265742785654203, 331.448838606281, array([-0.47450258,  0.22135402]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(dml_2sls.dml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:12<00:00, 74.44s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.10827665672668418, 0.4485805503659564, array([0.0954769 , 0.12107641]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(dml_rkhs.dml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:22<00:00,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:20<00:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:20<00:00,  4.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.044573847196636575, 0.9538932495759124, array([-0.06323899, -0.0259087 ]))\n",
      "Rep: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:18<00:00,  3.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:16<00:00,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:23<00:00,  4.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.06002980686551049, 0.9792778667860471, array([-0.07894168, -0.04111794]))\n",
      "Rep: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:22<00:00,  4.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:16<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:19<00:00,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.059110516418105, 0.985351471358598, array([-0.07808094, -0.04014009]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(dml_rkhs_chim.dml())\n",
    "print(dml_rkhs_ipw.dml())\n",
    "print(dml_rkhs_ipw_chim.dml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'n_epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\isaac\\Dropbox\\repos\\NNPIV\\nnpiv_venv\\lib\\site-packages\\joblib\\_utils.py\", line 72, in __call__\n    return self.func(**kwargs)\n  File \"c:\\Users\\isaac\\Dropbox\\repos\\NNPIV\\nnpiv_venv\\lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\isaac\\Dropbox\\repos\\NNPIV\\nnpiv_venv\\lib\\site-packages\\joblib\\parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"c:\\users\\isaac\\dropbox\\repos\\nnpiv\\nnpiv\\semiparametrics\\dml_mediated.py\", line 1043, in _process_fold\n    psi_hat_0 = self._scores_Y1(train_Y, 1-train_D, train_M, train_W, train_X, train_Z,\n  File \"c:\\users\\isaac\\dropbox\\repos\\nnpiv\\nnpiv\\semiparametrics\\dml_mediated.py\", line 969, in _scores_Y1\n    gamma_1 = self._npivfit_outcome(train_Y, train_D, train_X, train_Z)\n  File \"c:\\users\\isaac\\dropbox\\repos\\nnpiv\\nnpiv\\semiparametrics\\dml_mediated.py\", line 617, in _npivfit_outcome\n    bridge_1 = model_y1.fit(Z1, X1, Y1, **self.fitargs1)\nTypeError: fit() got an unexpected keyword argument 'n_epochs'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdml_agmm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdml\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\users\\isaac\\dropbox\\repos\\nnpiv\\nnpiv\\semiparametrics\\dml_mediated.py:1159\u001b[0m, in \u001b[0;36mDML_mediated.dml\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdml\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1151\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;124;03m    Perform Debiased Machine Learning for Nonparametric Instrumental Variables.\u001b[39;00m\n\u001b[0;32m   1153\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;124;03m        Estimated values, variances, and confidence intervals.\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1159\u001b[0m     theta, theta_var, confidence_interval, theta_cov_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_and_estimate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m theta[\u001b[38;5;241m0\u001b[39m], theta_var[\u001b[38;5;241m0\u001b[39m], confidence_interval[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\users\\isaac\\dropbox\\repos\\nnpiv\\nnpiv\\semiparametrics\\dml_mediated.py:1106\u001b[0m, in \u001b[0;36mDML_mediated._split_and_estimate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1104\u001b[0m kf \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_folds, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_seed\u001b[38;5;241m+\u001b[39mrep)\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1106\u001b[0m     fold_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthreading\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_fold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mD\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mM\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZ\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mD\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mM\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZ\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:   \n\u001b[0;32m   1116\u001b[0m     fold_results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreading\u001b[39m\u001b[38;5;124m'\u001b[39m)(\n\u001b[0;32m   1117\u001b[0m         delayed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_fold)(\n\u001b[0;32m   1118\u001b[0m             fold_idx, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1123\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m fold_idx, (train_index, test_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kf\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY))\n\u001b[0;32m   1124\u001b[0m     )                \n",
      "File \u001b[1;32mc:\\Users\\isaac\\Dropbox\\repos\\NNPIV\\nnpiv_venv\\lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\isaac\\Dropbox\\repos\\NNPIV\\nnpiv_venv\\lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\isaac\\Dropbox\\repos\\NNPIV\\nnpiv_venv\\lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\isaac\\Dropbox\\repos\\NNPIV\\nnpiv_venv\\lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\isaac\\Dropbox\\repos\\NNPIV\\nnpiv_venv\\lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\isaac\\Dropbox\\repos\\NNPIV\\nnpiv_venv\\lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'n_epochs'"
     ]
    }
   ],
   "source": [
    "print(dml_agmm.dml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubly_robust(X, T, Y):\n",
    "    ps = LogisticRegression(C=1e6, max_iter=1000).fit(X, T).predict_proba(X)[:, 1]\n",
    "    mask1 = np.where(T==1)[0]\n",
    "    mask0 = np.where(T==0)[0]\n",
    "    mu0 = LinearRegression().fit(X[mask0,], Y[mask0]).predict(X)\n",
    "    mu1 = LinearRegression().fit(X[mask1,], Y[mask1]).predict(X)\n",
    "    return (np.mean(T * (Y - mu1) / ps + mu1), np.mean((1 - T) * (Y - mu0) / (1 - ps) + mu0))\n",
    "\n",
    "\n",
    "y1, y0 = doubly_robust(X, D, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(y1)\n",
    "print(y0)\n",
    "print(y1 - y0)\n",
    "print(0.0895757991453447-y0)\n",
    "print(0.01544137589055832-y0)\n",
    "print(0.14523434238839902-y0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
